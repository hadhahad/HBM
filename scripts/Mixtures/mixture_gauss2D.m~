function [mu,sig,L,Smu,DEBUG]=mixture_gauss2D(d,k,sharp)
% Fitting a mixture of k Gaussians to the input data vector x,
% Prior of each component i the mixture is assumed to be etremely flat:
%   p(mu,sig)= N_mu(0,1/zeta*sig)* G_sig(a0,b0)
% with zeta=0, a0=0, b0=0; 
%
% input:
%   d    - Nx2 vector of data
%   k    - maximum number of components
%   sharp- initial sharpness of the components, relative to the spread of
%          the data. The variance of initial components is:
%             std(x)_k = (max(x)-min(x))/k/sharp
%          Higher values of "sharp" favors smaller clusters.
%
% output:
%   mu   - mean values of the components
%   sig  - variances of the components
%   L    - probabilities of membership in each component
%   Smu  - variances of the mean value estimates (var(mu))

if nargin<3
    sharp = 1;
    if nargin < 2
        k = 5;
    end
end

%% INITIALIZATION
data_size = size(d,1);
N = data_size(1);
l = zeros(k,N);

DATA.X = d(:,1);
DATA.Y = d(:,2);

% Split the space between min and max equally
minx = min(d(:,1));
maxx = max(d(:,1));
miny = min(d(:,2));
maxy = max(d(:,2));
distancex = (maxx-minx)/k;
distancey = (maxy-miny)/k;
mu = [(minx + distancex/2 : distancex : maxx); 
    (miny + distancey/2 : distancey : maxy)]' / 10;
Sigma_x = 1/(distancex/sharp)^2;
Sigma_y = 1/(distancey/sharp)^2;
Sigma = diag([Sigma_x, Sigma_y]);
Sigma = Sigma.*ones(2,2,k);

% Assume uniform spread of data between components
priorN = N/k;
alpha = priorN*ones(k,1)/N;

EM_p;
iter_num = 5;
for iter = 1:iter_num
    N_distr = zeros(k,1);
    sum_comps = zeros(1,N);
    for comp = 1:k
        l(comp,:) = mvnpdf([DATA.X DATA.Y], mu(comp,:), Sigma(:,:,comp))...
            * alpha(comp);
        sum_comps = sum_comps + l(comp,:);
    end
    l = l./sum_comps;
    N_distr = sum(l,2);
    for comp = 1:k
        sum_mat = zeros(2,2);
        mu(comp,:) = l(comp,:)*[DATA.X DATA.Y]/N_distr(comp);
        for i = 1:N
            sum_mat = sum_mat + ...
                l(comp,i).*(d(i,:)-mu(comp,:))'*(d(i,:)-mu(comp,:));
        end
        Sigma(:,:,comp) = sum_mat./N_distr(comp);
    end
    EM_new = sum(log(sum_comps));
end
%% Iterations
Lold = L;
Mu = ON*mu';

%% DEBUG
niter = 900;
DEBUG.mu = zeros(k,niter);
DEBUG.sig = zeros(k,niter);
DEBUG.sL = zeros(k,niter);

for ite = 1:niter

    % new L
    Om = ON*om';
    Lam = (-(X-Mu).^2.*Om + ON*log(om)' ); % log p()
    Lnn = exp(0.5*Lam-max(max(Lam)))*diag(w); % exp(log P())* w

    
    L = Lnn ./(sum(Lnn,2)*ones(1,k)+1e-10);
    sumL = sum(L,1)'+1e-10;
    
    % new mu
    mu = (L'*x)./(sumL+1e-10);
    Mu = ON*mu';

    % new Om
    alpha = a0 + sumL +1;
    beta = b0 + sum(L.*((X-Mu).^2),1)';
    
    om = alpha./beta;
    Smu = 1./(sumL.*om);
    
    % new weight
    w = sumL/sum(sumL);
    
    %te
    if 0
        figure(1);
        subplot(2,1,1);
        [hy,hx]=hist(x,100);

        sL = sum(L,1);
        fig=figure(1);
        hold off
        bar(hx,hy);
        hold on
        for kk=1:k
            fest = exp(-0.5*(hx-mu(kk)).^2*om(kk));
            f = w(kk)*fest/sum(fest)*N;
            plot(hx,f,'LineWidth',3);
        end
        title(['EM algorithm iteration ' num2str(ite)])
        
        subplot(2,1,2);
        hold off
        stem(x,L(:,1))
        hold on
        stem(x,L(:,2),'r')
        fig.PaperPosition = [-0.3 0 4.3 3];
        fig.PaperSize = [4 3];
        %         print(['mix_em' num2str(ite) ],'-dpdf')
        % pause
    end

    
    if 1
        DEBUG.mu(:,ite) = mu;
        DEBUG.sig(:,ite) = 1./om;
        DEBUG.sL(:,ite) = sumL;

    end
    if norm(Lold-L)<1e-3
        break
    end


    Lold=L;
end

%% output
sig = 1./om;
DEBUG.mu=DEBUG.mu(:,1:ite);
DEBUG.sig=DEBUG.sig(:,1:ite);
DEBUG.sL = DEBUG.sL(:,1:ite);
